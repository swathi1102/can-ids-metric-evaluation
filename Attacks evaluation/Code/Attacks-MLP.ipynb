{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a43a8c-c68b-4150-be6b-1e0de79d0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8462ba24-f638-4ec2-8832-847f3e5272e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directories\n",
    "train_directories = [\n",
    "    './Documents/Research/can-train-and-test/set_01/train_01/',\n",
    "    './Documents/Research/can-train-and-test/set_02/train_01/',\n",
    "    './Documents/Research/can-train-and-test/set_03/train_01/',\n",
    "    './Documents/Research/can-train-and-test/set_04/train_01/'\n",
    "]\n",
    "\n",
    "# Test files for DoS attack\n",
    "dos_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/DoS-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/DoS-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/DoS-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/DoS-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/DoS-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/DoS-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/DoS-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/DoS-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/DoS-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/DoS-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/DoS-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/DoS-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/DoS-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/DoS-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/DoS-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/DoS-2.csv'\n",
    "]\n",
    "\n",
    "# Test files for Force neutral attack\n",
    "fn_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/force-neutral-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/force-neutral-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/force-neutral-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/force-neutral-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/force-neutral-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/force-neutral-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/force-neutral-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/force-neutral-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/force-neutral-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/force-neutral-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/force-neutral-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/force-neutral-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/force-neutral-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/force-neutral-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/force-neutral-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/force-neutral-2.csv'\n",
    "]\n",
    "\n",
    "# Test files for RPM attack\n",
    "rpm_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/rpm-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/rpm-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/rpm-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/rpm-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/rpm-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/rpm-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/rpm-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/rpm-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/rpm-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/rpm-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/rpm-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/rpm-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/rpm-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/rpm-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/rpm-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/rpm-2.csv'\n",
    "]\n",
    "\n",
    "# Test files for standstill attack\n",
    "standstill_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/standstill-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_01_known_vehicle_known_attack/standstill-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/standstill-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_02_unknown_vehicle_known_attack/standstill-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/standstill-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_03_known_vehicle_unknown_attack/standstill-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/standstill-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_04_unknown_vehicle_unknown_attack/standstill-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/standstill-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/standstill-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/standstill-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/standstill-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/standstill-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/standstill-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/standstill-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/standstill-2.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2024fdfc-e89d-4aa7-b45a-3cc11a57a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load Data\n",
    "def load_data_from_directory(directory_path):\n",
    "    data_frames = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            data_frames.append(df)\n",
    "    return pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Function to Preprocess Data\n",
    "def hex_to_int(x):\n",
    "    try:\n",
    "        return int(str(x), 16)\n",
    "    except ValueError:\n",
    "        return 0  # Handle non-hexadecimal values\n",
    "        \n",
    "def preprocess_data(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).astype(np.int64) // 10**9\n",
    "    df['arbitration_id'] = df['arbitration_id'].apply(hex_to_int)\n",
    "    df['data_field'] = df['data_field'].apply(hex_to_int)\n",
    "    return df\n",
    "\n",
    "# Function to Extract Features and Labels\n",
    "def extract_features_labels(df, label_col='attack'):\n",
    "    X = df.drop(columns=label_col)\n",
    "    y = df[label_col]\n",
    "    return X, y\n",
    "\n",
    "# Function to load and combine attack files\n",
    "def load_combine_attack_files(files):\n",
    "    data_frames = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        data_frames.append(df)\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e27c47-541a-479b-ae3d-291c4af854c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Build and Train MLP Model\n",
    "def train_mlp(X_train, y_train):\n",
    "    # Standardize the Features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Convert labels to categorical if necessary\n",
    "    y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "    # Define the MLP model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Use the Input layer to specify the shape of the input\n",
    "    model.add(Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "    # Add hidden layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Record training start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the Model\n",
    "    model.fit(X_train_scaled, y_train_categorical, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    return model, scaler, training_time\n",
    "\n",
    "# Function to Test MLP Model\n",
    "def test_mlp(model, scaler, X_test, y_test):\n",
    "    # Standardize the Features\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert labels to categorical if necessary\n",
    "    y_test_categorical = to_categorical(y_test, num_classes=model.output_shape[1])\n",
    "\n",
    "    # Record testing start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Predict on Test Data\n",
    "    y_test_pred_probs = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate testing time\n",
    "    testing_time = time.time() - start_time\n",
    "    \n",
    "    y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Evaluate Test Performance\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    mcc_test = matthews_corrcoef(y_test, y_test_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    recall_test = recall_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    f1_test = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    informedness_test = recall_test - (1 - recall_test)\n",
    "    markedness_test = precision_test - (1 - precision_test)\n",
    "\n",
    "    return {\n",
    "        'conf_matrix': conf_matrix_test,\n",
    "        'mcc': mcc_test,\n",
    "        'accuracy': accuracy_test,\n",
    "        'precision': precision_test,\n",
    "        'recall': recall_test,\n",
    "        'f1_score': f1_test,\n",
    "        'informedness': informedness_test,\n",
    "        'markedness': markedness_test,\n",
    "        'testing_time': testing_time\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212825d3-047a-4afa-851c-33dd694d1c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1422s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0320\n",
      "Epoch 2/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1624s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0262\n",
      "Epoch 3/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1725s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0258\n",
      "Epoch 4/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1655s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0255\n",
      "Epoch 5/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1735s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0251\n",
      "Epoch 6/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1670s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0250\n",
      "Epoch 7/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1729s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0250\n",
      "Epoch 8/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1728s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0249\n",
      "Epoch 9/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1685s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0248\n",
      "Epoch 10/10\n",
      "\u001b[1m773634/773634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1099s\u001b[0m 1ms/step - accuracy: 0.9957 - loss: 0.0247\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training data\n",
    "df_train = pd.concat([load_data_from_directory(train_dir) for train_dir in train_directories], ignore_index=True)\n",
    "df_train = preprocess_data(df_train)\n",
    "X_train, y_train = extract_features_labels(df_train)\n",
    "\n",
    "# Train the MLP Model\n",
    "mlp_model, scaler, training_time = train_mlp(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c7b11d-3477-4cba-9755-037049cb10ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_time.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  # For saving the model\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(mlp_model, 'mlp_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(training_time,'training_time.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee7c8c2-5703-4ac0-bbb3-47e33069065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297670/297670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 1ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (DOS Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 622.42 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 97.13%\n",
      "Precision: 97.15%\n",
      "Recall: 97.13%\n",
      "F1-Score: 96.62%\n",
      "Matthews Correlation Coefficient: 0.6520\n",
      "Informedness: 0.9427\n",
      "Markedness: 0.9431\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data - DOS attack\n",
    "df_test = pd.concat([pd.read_csv(file) for file in dos_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (DOS Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb61d740-19b0-4a33-9748-53e774cb674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m537597/537597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 1ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Force neutral Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 1111.15 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.93%\n",
      "Precision: 99.92%\n",
      "Recall: 99.93%\n",
      "F1-Score: 99.92%\n",
      "Matthews Correlation Coefficient: 0.5488\n",
      "Informedness: 0.9986\n",
      "Markedness: 0.9984\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data - Force Neutral\n",
    "df_test = pd.concat([pd.read_csv(file) for file in fn_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Force neutral Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbd6fc8-b2ce-41d5-89bc-fcb18b84c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m487788/487788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (RPM Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 1057.89 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.85%\n",
      "Precision: 99.76%\n",
      "Recall: 99.85%\n",
      "F1-Score: 99.81%\n",
      "Matthews Correlation Coefficient: -0.0006\n",
      "Informedness: 0.9971\n",
      "Markedness: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in rpm_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (RPM Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db8c50d-2d5d-4b5f-a6cb-63d67bb56219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m345826/345826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Standstill Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 922.43 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.73%\n",
      "Precision: 99.54%\n",
      "Recall: 99.73%\n",
      "F1-Score: 99.63%\n",
      "Matthews Correlation Coefficient: -0.0009\n",
      "Informedness: 0.9946\n",
      "Markedness: 0.9908\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in standstill_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Standstill Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb20c8f-3e9d-46fd-8505-297a3b5ff92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test files for DoS attack\n",
    "double_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/double-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/double-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/double-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/double-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/double-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/double-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/double-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/double-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/double-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/double-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/double-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/double-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/double-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/double-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/double-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/double-2.csv'\n",
    "]\n",
    "\n",
    "# Test files for Force neutral attack\n",
    "triple_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/triple-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/triple-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/triple-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/triple-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/triple-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/triple-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/triple-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/triple-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/triple-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/triple-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/triple-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/triple-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/triple-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/triple-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/triple-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/triple-2.csv'\n",
    "]\n",
    "\n",
    "fuzzing_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/fuzzing-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/fuzzing-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/fuzzing-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/fuzzing-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/fuzzing-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/fuzzing-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/fuzzing-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/fuzzing-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/fuzzing-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_01_known_vehicle_known_attack/fuzzing-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/fuzzing-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_02_unknown_vehicle_known_attack/fuzzing-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/fuzzing-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_03_known_vehicle_unknown_attack/fuzzing-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/fuzzing-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_04_unknown_vehicle_unknown_attack/fuzzing-2.csv'\n",
    "]\n",
    "\n",
    "interval_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/interval-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/interval-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/interval-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/interval-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/interval-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/interval-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/interval-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/interval-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/interval-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/interval-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/interval-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/interval-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/interval-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/interval-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/interval-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/interval-2.csv'\n",
    "]\n",
    "\n",
    "speed_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/speed-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/speed-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/speed-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/speed-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/speed-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/speed-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/speed-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/speed-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/speed-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/speed-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/speed-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/speed-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/speed-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/speed-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/speed-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/speed-2.csv'\n",
    "]\n",
    "\n",
    "systematic_files = [\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/systematic-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_03_known_vehicle_unknown_attack/systematic-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/systematic-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_01/test_04_unknown_vehicle_unknown_attack/systematic-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/systematic-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_01_known_vehicle_known_attack/systematic-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/systematic-3.csv',\n",
    "    './Documents/Research/can-train-and-test/set_02/test_02_unknown_vehicle_known_attack/systematic-4.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/systematic-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/systematic-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/systematic-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/systematic-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/systematic-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/systematic-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/systematic-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/systematic-2.csv'\n",
    "]\n",
    "\n",
    "rpmaccessory_files = [\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/rpm-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/rpm-accessory-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/rpm-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/rpm-accessory-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/rpm-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/rpm-accessory-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/rpm-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/rpm-accessory-2.csv'\n",
    "]\n",
    "\n",
    "speedaccessory_files = [\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/speed-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_01_known_vehicle_known_attack/speed-accessory-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/speed-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_04/test_02_unknown_vehicle_known_attack/speed-accessory-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/speed-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_03_known_vehicle_unknown_attack/speed-accessory-2.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/speed-accessory-1.csv',\n",
    "    './Documents/Research/can-train-and-test/set_03/test_04_unknown_vehicle_unknown_attack/speed-accessory-2.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ee45fb-f152-45c2-af8a-d41d45dbdbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m483796/483796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m713s\u001b[0m 1ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Double Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16072.18 seconds\n",
      "Testing Time: 1043.06 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.59%\n",
      "Precision: 99.26%\n",
      "Recall: 99.59%\n",
      "F1-Score: 99.42%\n",
      "Matthews Correlation Coefficient: -0.0012\n",
      "Informedness: 0.9917\n",
      "Markedness: 0.9851\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in double_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Double Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098a0260-3017-4aaf-a1cc-2f36e95b7681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m460160/460160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Triple Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 1162.51 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 98.81%\n",
      "Precision: 98.33%\n",
      "Recall: 98.81%\n",
      "F1-Score: 98.33%\n",
      "Matthews Correlation Coefficient: 0.1759\n",
      "Informedness: 0.9761\n",
      "Markedness: 0.9666\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in triple_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Triple Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d66078-ac0f-42a5-831b-51b5be0c57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m350927/350927\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Fuzzing Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 851.94 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 98.71%\n",
      "Precision: 98.68%\n",
      "Recall: 98.71%\n",
      "F1-Score: 98.49%\n",
      "Matthews Correlation Coefficient: 0.6639\n",
      "Informedness: 0.9742\n",
      "Markedness: 0.9736\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in fuzzing_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Fuzzing Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a946645e-640f-4a7b-aea2-8edfa65c9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m417571/417571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m776s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Interval Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16346.62 seconds\n",
      "Testing Time: 1042.50 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.76%\n",
      "Precision: 99.76%\n",
      "Recall: 99.76%\n",
      "F1-Score: 99.75%\n",
      "Matthews Correlation Coefficient: 0.9300\n",
      "Informedness: 0.9952\n",
      "Markedness: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in interval_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Interval Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585f6818-f040-4dd3-8c3c-9c112985c9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m684694/684694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1101s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Speed Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16072.18 seconds\n",
      "Testing Time: 1421.09 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.78%\n",
      "Precision: 99.61%\n",
      "Recall: 99.78%\n",
      "F1-Score: 99.69%\n",
      "Matthews Correlation Coefficient: -0.0008\n",
      "Informedness: 0.9955\n",
      "Markedness: 0.9923\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in speed_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Speed Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5244e0fc-8b4b-4a3c-8069-29d09da6291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m309890/309890\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 1ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Systematic Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16072.18 seconds\n",
      "Testing Time: 682.43 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.41%\n",
      "Precision: 99.34%\n",
      "Recall: 99.41%\n",
      "F1-Score: 99.27%\n",
      "Matthews Correlation Coefficient: 0.5124\n",
      "Informedness: 0.9882\n",
      "Markedness: 0.9868\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in systematic_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Systematic Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b32617cb-b21d-4a72-8822-bd8987485b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52784/52784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (RPM Accessory Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16072.18 seconds\n",
      "Testing Time: 142.15 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.77%\n",
      "Precision: 99.58%\n",
      "Recall: 99.77%\n",
      "F1-Score: 99.67%\n",
      "Matthews Correlation Coefficient: -0.0007\n",
      "Informedness: 0.9953\n",
      "Markedness: 0.9917\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in rpmaccessory_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (RPM Accessory Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a47b74-ca1f-4102-8155-ac4e2ff2cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62815/62815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2ms/step\n",
      "\n",
      "===============================================================================\n",
      "\n",
      "Testing Metrics (Speed Accessory Attack Test Files):\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training Time: 16072.18 seconds\n",
      "Testing Time: 137.91 seconds\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Accuracy: 99.61%\n",
      "Precision: 99.28%\n",
      "Recall: 99.61%\n",
      "F1-Score: 99.45%\n",
      "Matthews Correlation Coefficient: -0.0010\n",
      "Informedness: 0.9923\n",
      "Markedness: 0.9857\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess testing data\n",
    "df_test = pd.concat([pd.read_csv(file) for file in speedaccessory_files], ignore_index=True)\n",
    "df_test = preprocess_data(df_test)\n",
    "X_test, y_test = extract_features_labels(df_test)\n",
    "\n",
    "# Benchmark testing the Multi Layer Perceptron Model\n",
    "test_metrics = test_mlp(mlp_model, scaler, X_test, y_test)\n",
    "\n",
    "# Print Combined Testing Metrics\n",
    "print(f\"\\n===============================================================================\")\n",
    "print(f\"\\nTesting Metrics (Speed Accessory Attack Test Files):\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n",
    "print(f\"Testing Time: {test_metrics['testing_time']:.2f} seconds\")\n",
    "print(f\"\\n-----------------------------------------------------------------------\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Precision: {test_metrics['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {test_metrics['recall'] * 100:.2f}%\")\n",
    "print(f\"F1-Score: {test_metrics['f1_score'] * 100:.2f}%\")\n",
    "print(f\"Matthews Correlation Coefficient: {test_metrics['mcc']:.4f}\")\n",
    "print(f\"Informedness: {test_metrics['informedness']:.4f}\")\n",
    "print(f\"Markedness: {test_metrics['markedness']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6899016-f24b-44ee-9fc9-cc92df558e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be179277-b3ea-4569-8d0c-ddef4fa3d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
